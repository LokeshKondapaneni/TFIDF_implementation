{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9464I-uxLiw"
   },
   "source": [
    "# TFIDF Implementation on a corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have implemented TFIDF vectorization on a test corpus. The first task is implementation of TFIDF and the second task considers TFIDF implementation to get top features only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg2ooa4DxLiz"
   },
   "source": [
    "### 1. Use all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnV82tg1xLi0"
   },
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUsYm9wjxLi1"
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjuCcJwXxLjJ"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-cGTQPLmpJT"
   },
   "outputs": [],
   "source": [
    "# Reference for fit and transform methods: Assignment_3_Reference.ipynb from https://www.appliedaicourse.com\n",
    "class tfidf_implement():\n",
    "  ''' Implementation of tfidf '''\n",
    "  def __init__(self):\n",
    "    vocab = []\n",
    "    idf_values = []\n",
    "\n",
    "  def fit(self, dataset):\n",
    "     ''' Fit dataset - takes dataset as input, returns dictionary \n",
    "     of unique words and respective indices from whole dataset in alphabetical order '''\n",
    "     if isinstance(dataset, list):\n",
    "      unique_words = set()\n",
    "      for row in dataset:\n",
    "        word_list = row.split(\" \")\n",
    "        for word in word_list:\n",
    "          if len(word)<2:\n",
    "            continue\n",
    "          unique_words.add(word)\n",
    "      sort_words = sorted(list(unique_words))\n",
    "      # Stored in __init__ so it can be used by other methods and for ease of getting vocab when user wants them\n",
    "      self.vocab = {j:i for i,j in enumerate(sort_words)}\n",
    "      return\n",
    "     else:\n",
    "      print(\"Please give list of strings\")\n",
    "\n",
    "  def idf(self, dataset):\n",
    "    ''' Compute idf values of all words returned by fit. Returns idf values and \n",
    "    order of idf values is maintained as per dictionary of fit\\n \n",
    "    Note: idf uses dictionary of fit, so should run fit first'''\n",
    "    # Split sentences, list of words are taken\n",
    "    words = [[word for word in row.split(\" \")] for row in dataset]\n",
    "    idf_values = []\n",
    "    # for every word in vocab\n",
    "    for t in self.vocab:\n",
    "      count = 0\n",
    "      # for every row of split dataset, words\n",
    "      for doc in words:\n",
    "        # if vocab word is present in that row of dataset\n",
    "        if t in doc:\n",
    "          count += 1\n",
    "      # idf is calculated\n",
    "      idf = 1 + math.log((1+len(dataset))/(1+count))\n",
    "      # idf values are appended \n",
    "      idf_values.append(idf)\n",
    "    # Stored to be accessed easily by other methods in class and for ease of getting idf_values when user wants them\n",
    "    self.idf_values = idf_values\n",
    "    return\n",
    "      \n",
    "  def transform(self, dataset):\n",
    "    ''' Input dataset, returns sparse matrix of tfidf values\\n\n",
    "    Note: Should run fit and idf functions before running transform '''\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, list):\n",
    "      for idx, row in enumerate(tqdm(dataset)):\n",
    "        row = row.split(\" \")\n",
    "        word_list = dict(Counter(row))\n",
    "        for word, freq in word_list.items():\n",
    "          if len(word)<2:\n",
    "            continue\n",
    "          col_idx = self.vocab.get(word, -1)\n",
    "          if col_idx !=-1:\n",
    "            rows.append(idx)\n",
    "            columns.append(col_idx)\n",
    "            # tfidf values are computed\n",
    "            # idf_values has same index as taken from vocab's values, since its values are appended wrt vocab words\n",
    "            val = (freq/len(row)) * self.idf_values[col_idx]\n",
    "            values.append(val)\n",
    "      return normalize(csr_matrix((values,(rows,columns)), shape=(len(dataset), len(self.vocab))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "jlOKdrbpo5uQ",
    "outputId": "11579a32-f743-4805-a4d9-da095aaa8b67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 5704.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      " 0.38408524 0.         0.38408524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c1 = tfidf_implement()\n",
    "c1.fit(corpus)\n",
    "c1.idf(corpus)\n",
    "\n",
    "print(c1.transform(corpus).toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "JoKK3kW7jybx",
    "outputId": "391096f6-44e2-46a7-ebdf-76642dc2f7d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'is': 3,\n",
       " 'one': 4,\n",
       " 'second': 5,\n",
       " 'the': 6,\n",
       " 'third': 7,\n",
       " 'this': 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "NC4fwvjFjou1",
    "outputId": "c705fb49-9567-4a11-e9ca-a1fe671c6636"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.916290731874155,\n",
       " 1.2231435513142097,\n",
       " 1.5108256237659907,\n",
       " 1.0,\n",
       " 1.916290731874155,\n",
       " 1.916290731874155,\n",
       " 1.0,\n",
       " 1.916290731874155,\n",
       " 1.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idf values \n",
    "c1.idf_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMxBmVZExLjK"
   },
   "source": [
    "### 2. Select only top features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "NHxPLlwNxLjL",
    "outputId": "465cfb60-dadb-442b-e475-8f2383f777dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "# Below is the code to load the cleaned_strings pickle file provided\n",
    "# Here corpus is of list type\n",
    "\n",
    "import pickle\n",
    "with open('test_corpus.txt', 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    \n",
    "# printing the length of the corpus loaded\n",
    "print(\"Number of documents in corpus = \",len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_DJnnR3xLjR"
   },
   "outputs": [],
   "source": [
    "# Ref_1 : https://stackoverflow.com/questions/29216889/slicing-a-dictionary\n",
    "# Ref_2 : https://stackoverflow.com/questions/9919604/efficiently-calculate-word-frequency-in-a-string\n",
    "\n",
    "# Same as above class, only difference here is a new method pickTop(n) which gives top n words based on largest idf values\n",
    "\n",
    "class tfidf_implement2():\n",
    "  ''' Implementation 2 of tfidf '''\n",
    "\n",
    "  def __init__(self):\n",
    "    vocab = []\n",
    "    idf_values = []\n",
    "\n",
    "  def fit(self, dataset):\n",
    "    ''' Fit dataset - takes dataset as input, returns dictionary \n",
    "    of unique words and respective indices from whole dataset in alphabetical order '''\n",
    "    if isinstance(dataset, list):\n",
    "      unique_words = set()\n",
    "      for row in dataset:\n",
    "        word_list = row.split(\" \")\n",
    "        for word in word_list:\n",
    "          if len(word)<2:\n",
    "            continue\n",
    "          unique_words.add(word)\n",
    "      sort_words = sorted(list(unique_words))\n",
    "      self.vocab = {j:i for i,j in enumerate(sort_words)}\n",
    "      return self.vocab\n",
    "    else:\n",
    "      print(\"Please give list of strings\")\n",
    "\n",
    "  def idf(self, dataset):\n",
    "    ''' Compute idf values of all words returned by fit. Returns idf values and \n",
    "    order of idf values is maintained as per dictionary of fit\\n \n",
    "    Note: idf uses dictionary of fit, so should run fit first'''\n",
    "    words = [[word for word in row.split(\" \")] for row in dataset]\n",
    "    idf_values = []\n",
    "    for t in self.vocab:\n",
    "      count = 0\n",
    "      for doc in words:\n",
    "        if t in doc:\n",
    "          count += 1\n",
    "      idf = 1 + math.log((1+len(dataset))/(1+count))\n",
    "      idf_values.append(idf)\n",
    "    self.idf_values = idf_values\n",
    "    return\n",
    "  \n",
    "  def pickTop(self,n):\n",
    "    ''' Returs none, Picks top 'n' features based on idf values\\n \n",
    "    Note: fit and idf should be ran first'''\n",
    "    # Take numpy array of idf_values and call argsort to get indices of n largest idf values\n",
    "    idf = numpy.array(self.idf_values)\n",
    "    sort_idx = list(numpy.argsort(idf))[-n:]\n",
    "    # initialize new empty vocab and idf_values\n",
    "    new_vocab = []\n",
    "    new_idf = []\n",
    "    i = 0\n",
    "    # for every (key,value) pair in vocab\n",
    "    for item in self.vocab.items():\n",
    "      # if value of item, i.e index of that vocab is in list of sorted indices \n",
    "      if item[1] in sort_idx:\n",
    "        # append idf_value corresponding to the index in vocab\n",
    "        new_idf.append(idf[item[1]])\n",
    "        # Append tupple with same key and value is the new index \n",
    "        new_vocab.append((item[0],i))\n",
    "        i = i+1\n",
    "    # Overwrite vocab and idf_values in __init__ to be used for further methods and ease of getting values if user wants\n",
    "    self.vocab = dict(new_vocab)\n",
    "    self.idf_values = new_idf\n",
    "\n",
    "  def transform(self, dataset):\n",
    "    ''' Input dataset, returns sparse matrix of tfidf values\\n\n",
    "    Note: Should run fit and idf functions before running transform '''\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, list):\n",
    "      for idx, row in enumerate(tqdm(dataset)):\n",
    "        row = row.split(\" \")\n",
    "        word_list = dict(Counter(row))\n",
    "        for word, freq in word_list.items():\n",
    "          if len(word)<2:\n",
    "            continue\n",
    "          col_idx = self.vocab.get(word, -1)\n",
    "          if col_idx !=-1:\n",
    "            rows.append(idx)\n",
    "            columns.append(col_idx)\n",
    "            val = (freq/len(row)) * self.idf_values[col_idx]\n",
    "            values.append(val)\n",
    "      return normalize(csr_matrix((values,(rows,columns)), shape=(len(dataset), len(self.vocab))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tIgvKDqnjonb",
    "outputId": "5cebfd60-8fc7-417b-aeb7-ab188db8d614"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 746/746 [00:00<00:00, 102915.86it/s]\n"
     ]
    }
   ],
   "source": [
    "c2 = tfidf_implement2()\n",
    "c2.fit(corpus)\n",
    "c2.idf(corpus)\n",
    "c2.pickTop(50)\n",
    "output = c2.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "gMRg8PqBkWeN",
    "outputId": "1d5e8203-cc03-4713-83bf-a98d26ddf2b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gone': 0,\n",
       " 'gosh': 1,\n",
       " 'goth': 2,\n",
       " 'gotta': 3,\n",
       " 'gotten': 4,\n",
       " 'government': 5,\n",
       " 'grade': 6,\n",
       " 'gradually': 7,\n",
       " 'grainy': 8,\n",
       " 'granted': 9,\n",
       " 'graphics': 10,\n",
       " 'grasp': 11,\n",
       " 'grates': 12,\n",
       " 'halfway': 13,\n",
       " 'ham': 14,\n",
       " 'handle': 15,\n",
       " 'handles': 16,\n",
       " 'hang': 17,\n",
       " 'hankies': 18,\n",
       " 'hanks': 19,\n",
       " 'happiness': 20,\n",
       " 'happy': 21,\n",
       " 'harris': 22,\n",
       " 'hatred': 23,\n",
       " 'havilland': 24,\n",
       " 'hay': 25,\n",
       " 'hayao': 26,\n",
       " 'hayworth': 27,\n",
       " 'hbo': 28,\n",
       " 'heads': 29,\n",
       " 'hearts': 30,\n",
       " 'heartwarming': 31,\n",
       " 'heche': 32,\n",
       " 'heels': 33,\n",
       " 'heist': 34,\n",
       " 'helen': 35,\n",
       " 'hellish': 36,\n",
       " 'helms': 37,\n",
       " 'help': 38,\n",
       " 'helping': 39,\n",
       " 'hendrikson': 40,\n",
       " 'hernandez': 41,\n",
       " 'hero': 42,\n",
       " 'heroes': 43,\n",
       " 'heroine': 44,\n",
       " 'heroism': 45,\n",
       " 'hes': 46,\n",
       " 'hide': 47,\n",
       " 'higher': 48,\n",
       " 'zombiez': 49}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "BJftudbJYXpQ",
    "outputId": "6affd123-6bb7-4295-aff6-043e546cb0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746, 50)\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "qCK-FrVFlpX4",
    "outputId": "cddadab1-a6ff-42e2-a679-934b4907e9fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872,\n",
       " 6.922918004572872]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.idf_values"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
